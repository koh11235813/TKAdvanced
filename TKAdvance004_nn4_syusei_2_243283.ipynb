{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNFrk5CBSMNY"
      },
      "source": [
        "# ニューラルネットワークの実装 2 （回帰）\n",
        "\n",
        "本章では TensorFlow を使用して回帰の問題設定に対する実装方法を学んでいきます。基本的には分類と同様の手順で実装を行うことが可能です。  \n",
        "できる方は本章を読み進める前にご自身で実装を行ってみて下さい。  \n",
        "\n",
        "本章では少し発展的な TensorFlow の実装方法についても紹介していきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G31zY-4SrOc"
      },
      "source": [
        "## 本章の構成\n",
        "\n",
        "- データセットの準備\n",
        "- モデルの定義\n",
        "- 目的関数・最適化手法の選択\n",
        "- モデルの学習\n",
        "- 予測精度の評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHlMmWlCS59q"
      },
      "source": [
        "## データセットの準備\n",
        "\n",
        "必要なモジュールのインポートとデータセットの読み込みを行います。  \n",
        "今回使用するデータセットは scikit-learn に準備されているボストン市の家賃に関するデータセットを用います。  \n",
        "\n",
        "目的変数に家賃 (Target)、入力変数に住宅に関する情報を持つデータセットで、家賃を予測する回帰の問題設定になります。  \n",
        "\n",
        "データセットの詳細に関しては[こちら](https://scikit-learn.org/stable/datasets/index.html#boston-dataset)を参照して下さい。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbVP3hIeTJ-Q"
      },
      "source": [
        "# 必要なモジュールの読み込み\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "dataset = fetch_california_housing()"
      ],
      "metadata": {
        "id": "SuiK5DH2qBHU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colms_name = dataset.feature_names\n",
        "x = dataset.data\n",
        "t = dataset.target"
      ],
      "metadata": {
        "id": "BvkMip-f5CV5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OppjwbFUbaUB"
      },
      "source": [
        "# 読み込んだデータセットをデータフレーム形式に変換\n",
        "df = pd.DataFrame(data=x, columns=colms_name)\n",
        "df['Target'] = t\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFMp15qUhbzO"
      },
      "source": [
        "### データセットの確認\n",
        "\n",
        "ニューラルネットワークを含む機械学習のアルゴリズムはどのようなデータセットを使用するかが非常に重要です。また、適切な前処理を加えることによって精度向上に繋がる場合は多くあります。本章では前処理の実装は行いませんがデータセットの中身を確認方法を再度確認しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KIfGFaoVNFg"
      },
      "source": [
        "# サンプル数（行数）、入力・目的変数の数（列数）の確認\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OUxlr99gukv"
      },
      "source": [
        "# 目的変数の分布の確認\n",
        "sns.histplot(df['Target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWTe3JBiVXa"
      },
      "source": [
        "分布を確認すると値が 50 以上のものが少しその周辺よりも多く、外れ値のようになっています。このようなケースでは、$3 \\sigma$ 法などを用いて、外れ値除去を行い、問題設定を切り分けるアプローチが考えられます。  \n",
        "\n",
        "続いて相関係数を確認しましょう。相関係数は `corr()` メソッドで取得可能です。また、取得した相関係数を Seaborn の heatmap() 関数を用いて可視化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aReDe1QJjPP3"
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "sns.heatmap(df.corr(), annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcCCiYzjPVP"
      },
      "source": [
        "入力変数同士で相関係数が高いものが存在する事は[多重共線性](https://ja.wikipedia.org/wiki/%E9%87%8D%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90)などを引き起こすなどの理由から好ましくありません。今回は特別相関係数の高い入力変数は存在しませんが、必要であれば相関係数の値から入力変数の選定を行います。  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ53OYw9l_r0"
      },
      "source": [
        "### 入力変数と目的変数の切り分け\n",
        "\n",
        "分類の問題設定と同様に入力変数と目的変数の切り分けを行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5YWhMx9l_mZ"
      },
      "source": [
        "# 入力変数（Target 列以外の列を取得）\n",
        "x = df.drop('Target', axis=1)\n",
        "\n",
        "# 目的変数（Target の列のみを取得）\n",
        "t = df['Target']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZco7PRRl_hF"
      },
      "source": [
        "x.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB4UBVNbmT5E"
      },
      "source": [
        "### TensorFlow で計算できるデータの形式に変換\n",
        "\n",
        "分類ではラベルの最小値が 0 である必要がありましたが、今回の回帰の問題設定では特にその必要はありません。しかし、**データは NumPy の ndarray オブジェクトで定義されている必要があります。**  \n",
        "\n",
        "`values` 属性から取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hQ37rull_bi"
      },
      "source": [
        "type(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUbdJRwbmvC1"
      },
      "source": [
        "x = x.values\n",
        "t = t.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUqQWyamwNO"
      },
      "source": [
        "type(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrHwXBUJm_jc"
      },
      "source": [
        "入力値のデータ型は `numpy.float32`、回帰の問題では目標値のデータ型も `numpy.float32` である必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Pkzyb5nB2-"
      },
      "source": [
        "x.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v82NwCvpnDOH"
      },
      "source": [
        "# それぞれのデータ型を変換\n",
        "x = x.astype('float32')\n",
        "t = t.astype('float32')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drrbpHGOnEH9"
      },
      "source": [
        "x.dtype, t.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pWUw-gLnEym"
      },
      "source": [
        "### 学習用データセットとテスト用データセットに分割\n",
        "\n",
        "モデルの学習を行うためのデータセットと、予測精度を測るためのデータセットへの切り分けを行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTnlLY3TnCKA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 学習用データセットとテスト用データセットの分割\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, train_size=0.7, random_state=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHmGaqvAnlOd"
      },
      "source": [
        "分割が完了した後は、それぞれのデータセットのサンプル数を確認し、正常に分割できていることを確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwexDlqLnhho"
      },
      "source": [
        "x_train.shape, x_train.dtype, x_test.shape, x_test.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SzmGpKXnjOU"
      },
      "source": [
        "t_train.shape, t_train.dtype, t_test.shape, t_test.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eLWTwA2nqth"
      },
      "source": [
        "これで学習を行うためのデータセットの準備が整いました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIVb3OmknjdG"
      },
      "source": [
        "## モデルの定義\n",
        "\n",
        "まずは前章のコードを参考にして、ご自身でモデルの定義を行って下さい。その後に資料の続きを確認していきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9NlxCG6oy1U"
      },
      "source": [
        "import os, random\n",
        "\n",
        "# シードを固定するための関数の定義\n",
        "def reset_seed(seed=0):\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    random.seed(seed) # random関数のシードを固定\n",
        "    np.random.seed(seed) # numpyのシードを固定\n",
        "    tf.random.set_seed(seed) # tensorflowのシードを固定"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBzjBUj0pASb"
      },
      "source": [
        "前章の分類の問題設定に対し使用した下記のコードを今回の問題設定に合わして変更を加えましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcoavkc5nCME"
      },
      "source": [
        "# このコードに変更を加える\n",
        "\n",
        "from tensorflow.keras import models,layers\n",
        "# シードの固定\n",
        "reset_seed(0)\n",
        "\n",
        "# モデルのインスタンス化\n",
        "model = models.Sequential()\n",
        "\n",
        "# モデルの構築\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(30,)))\n",
        "model.add(layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxJ5mDBwosAa"
      },
      "source": [
        "前回と今回の異なる点は下記になります。  \n",
        "\n",
        "- 使用するデータセットが異なる\n",
        "- 分類ではなく、回帰の問題設定\n",
        "\n",
        "変更したコードを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jIdqiGyplNV"
      },
      "source": [
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouRc_IaYpKMd"
      },
      "source": [
        "# 変更後のコード\n",
        "# シードの固定\n",
        "reset_seed(0)\n",
        "\n",
        "# モデルのインスタンス化\n",
        "model = models.Sequential()\n",
        "\n",
        "# モデルの構築\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(8,)))\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWAvW9bhpKRO"
      },
      "source": [
        "変更点は下記になります。  \n",
        "\n",
        "- 入力層のノードの数\n",
        "- 出力層のノードの数\n",
        "- 出力層のソフトマックス関数の除去\n",
        "\n",
        "今回のデータセットの入力変数の数は 13 であるため、その数に合わせて入力層の `input_shape` の引数を変更する必要がありました。また、出力層の `units` の引数も家賃の 1 つの数値を予測するため変更する必要があります。今回の問題設定は回帰で数値を予測するため、ソフトマックス関数を適用して、値を 0~1 の間に変換する必要がありません。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVEnQ2wCmRTa"
      },
      "source": [
        "### Functional API を用いてモデルの定義\n",
        "\n",
        "これまでは Sequential API を用いて実装を行ってきましたが、少し発展的な **Functional API** を用いての実装方法を紹介します。本講座では基本的には Sequential API を用いて実装を行いますが、何か発展的な実装を行う際には Functional API が必要となります。ここで基礎的な実装方法を理解しましょう。  \n",
        "\n",
        "#### Functional API の概要\n",
        "\n",
        "Functional API では Sequectial API と異なり入力値、出力値、層、モデルなどの共有が可能となります。これにより fucntional API ではより柔軟にネットワークの構築を行うことが可能になります。  \n",
        "\n",
        "例えば 3 層のニューラルネットワークを作成した際に 1 層目の出力を 2 層目を飛ばして、3 層目の入力として再度使用することなどが可能になります。  \n",
        "\n",
        "また、[オートエンコーダ (autoencoder)](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%80) と呼ばれるアルゴリズムのような、エンコーダーとデコーダーの 2 つのモデルを持つような構造のモデルもモデル自体共有することにより構築が可能となります。  \n",
        "\n",
        "![functional API でのモデル構築例](https://www.tensorflow.org/guide/keras/functional_files/output_ef7ac19c83be_0.png)\n",
        "\n",
        "*出典 : [Google LLC](https://www.tensorflow.org/guide/keras/functional)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUR31h4yQDP9"
      },
      "source": [
        "#### Functional API の実装\n",
        "\n",
        "記述方法に大きく違いはありませんが下記の点に注意する必要がある。  \n",
        "\n",
        "- 入力値の形を定義する `Input` を記述する必要がある\n",
        "- `layers.Dense(10, activation='relu')(inputs)` のように層に対応する入力値を記述する必要がある\n",
        "- 層の計算を変数に格納する必要がある\n",
        "\n",
        "実際に Functional API を用いて実装を行いましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hogB87KQQDQA"
      },
      "source": [
        "from tensorflow.keras import models, layers, Input\n",
        "\n",
        "# シードの固定\n",
        "reset_seed(0)\n",
        "\n",
        "# モデルの構築\n",
        "inputs = Input(shape=(8,)) # 入力値の形の定義\n",
        "x = layers.Dense(3, activation='relu')(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs, name='linear_model')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3FJ0j5qS8N"
      },
      "source": [
        "今回は Functional API を用いて比較的シンプルなモデルの構築を行いました。複雑なモデルの構築方法などに関してはこちらの[公式ドキュメント](https://www.tensorflow.org/guide/keras/functional)を参照して下さい。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIkWNRgcp9e8"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEeFEnfYONxM"
      },
      "source": [
        "## 目的関数・最適化手法の選択\n",
        "\n",
        "### 最適化手法の選択\n",
        "\n",
        "モデルの定義以外は sequential API と同様の記述方法になります。\n",
        "`tf.keras.optimizers` モジュールを使用して、最適化手法の選択を行います。  \n",
        "今回は [Adam](https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95#Adam) と呼ばれる最適化手法を使用します。  \n",
        "\n",
        "最適化手法も一種のハイパーパラメータと呼ぶことができます。最適化手法を変更することによって、パラメータの更新の方法が異なります。Adam は比較的効率よく学習を行うことができると経験的に言われています。  \n",
        "うまく学習が進まない場合は最適化手法や学習係数を変更してみて、学習結果を確認してみて下さい。  \n",
        "\n",
        "\n",
        "### 目的関数の選択\n",
        "\n",
        "今回の問題設定は回帰であるため、目的関数には**平均二乗誤差 (mean squared error ; mse)** を用います。  \n",
        "評価には**二乗平均平方根誤差 (root mean squared error ; rmse)**を使用します。二乗平均平方根誤差は平均二乗誤差に $\\sqrt{}$ を適用し、スケールを戻したものになります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTPYnvV3MIFW"
      },
      "source": [
        "# optimizer　の設定\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAiiKd5uzxXm"
      },
      "source": [
        "## モデルの学習\n",
        "\n",
        "前章でもお伝えましたが、モデルの学習時にはミニバッチ学習を行う際のバッチサイズとエポック数を定義する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooxyKSAAQDQD",
        "scrolled": true
      },
      "source": [
        "# バッチサイズとエポック数の定義\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# 学習の実行\n",
        "history = model.fit(x_train, t_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVuHY1yJztnx"
      },
      "source": [
        "## 予測精度の評価\n",
        "\n",
        "学習結果を取得し、モデルの予測精度を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKX6OJ900Sny"
      },
      "source": [
        "results = pd.DataFrame(history.history)\n",
        "results.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOoxu6mv0ShZ"
      },
      "source": [
        "# 損失を可視化\n",
        "results[['loss', 'val_loss']].plot(title='loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdQfiEUk3l0M"
      },
      "source": [
        "テスト用データセットに対する二乗平均平方根誤差　(以後 RMSE) の値が約 1.236 となっている事がわかります。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofw5sG-9t9KL"
      },
      "source": [
        "## 練習問題 本章のまとめ\n",
        "\n",
        "本章で学んだ内容を復習しましょう。下記の内容を次のセルに記述し、実行結果を確認してください。（必要に応じてセルの追加を行ってください。）\n",
        "\n",
        "今回のデータセット（ボストン市の家賃に関するデータ）を用いて、家賃を予測するモデルの構築を再度行って下さい。また、ハイパーパラメータの調整を行い、モデルの予測精度向上を行いましょう。目標となる RMSE は 1 以下です。（目的変数・入力変数、データセットの切り分けなどの情報は前述の内容を確認して下さい。）  \n",
        "\n",
        "実装は下記の流れを参照して下さい。  \n",
        "\n",
        "- データセットの準備\n",
        "- モデルの定義\n",
        "- 目的関数・最適化手法の選択\n",
        "- モデルの学習\n",
        "- 予測精度の評価\n",
        "- ハイパーパラメータの調整  \n",
        "\n",
        "*精度向上のヒント*\n",
        "\n",
        "- 層・ノードの数の変更\n",
        "- バッチノーマリゼーションの層の追加\n",
        "- エポック数の調整\n",
        "- 学習係数の調整\n",
        "- 最適化手法の変更\n",
        "- データセットに対する前処理（入力変数の選択など）"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "dataset = fetch_california_housing()\n",
        "colms_name = dataset.feature_names\n",
        "x = dataset.data\n",
        "t = dataset.target"
      ],
      "metadata": {
        "id": "znUBSssw_tK8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSGGs9Kb538e"
      },
      "source": [
        "# 読み込んだデータセットをデータフレーム形式に変換\n",
        "df = pd.DataFrame(data=x, columns=colms_name)\n",
        "df['Target'] = t\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWekH3n60iNB"
      },
      "source": [
        "#### データセットの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V3o0bZP01Na"
      },
      "source": [
        "# それぞれのデータ型を変換\n",
        "x = x.astype('float32')\n",
        "t = t.astype('float32')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0O4VwHp01Nk"
      },
      "source": [
        "x.dtype, t.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr-AoGbS01Nr"
      },
      "source": [
        "**学習用データセットとテスト用データセットに分割**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AIdVIKb01Nz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, train_size=0.7, random_state=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6zLoSOW01N9"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duCQ_MIw01OY"
      },
      "source": [
        "#### モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdy3Keks01OZ"
      },
      "source": [
        "import os, random\n",
        "\n",
        "# シードを固定するための関数の定義\n",
        "def reset_seed(seed=0):\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    random.seed(seed) # random関数のシードを固定\n",
        "    np.random.seed(seed) # numpyのシードを固定\n",
        "    tf.random.set_seed(seed) # tensorflowのシードを固定"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFYTPnJIDpUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar3BvKOY01PU"
      },
      "source": [
        "#### 目的関数・最適化手法の選択"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zK7sG02E0yev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzIdsY8c01Pa"
      },
      "source": [
        "#### モデルの学習"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Zw6HSSQ0zKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS5OW3Mo01Pk"
      },
      "source": [
        "#### 予測精度の評価"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqI2vfQ-0z8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ハイパーパラメータの調整"
      ],
      "metadata": {
        "id": "kKPTlohdLKgE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDr2urCk00yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TL26QbcNY4l"
      },
      "source": [
        "---\n",
        "© 株式会社キカガク及び国立大学法人 豊橋技術科学大学"
      ]
    }
  ]
}